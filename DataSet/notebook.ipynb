{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PY libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# basic funcs\n",
    "\"\"\"\n",
    "def default_steam():\n",
    "    steam.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "    steam = steam.sort_values(\"app_id\")\n",
    "\n",
    "def letters_count_update():\n",
    "    steam['letters_count'] = steam['review_text'].apply(lambda x: len(x))\n",
    "\n",
    "def comment_filter():\n",
    "    steam = steam[steam['letters_count'] > 10]\n",
    "    steam = steam[(steam['letters_count'] >= 25) | (steam['review_votes'] == 1)]\n",
    "    steam = steam.sort_values('letters_count')\n",
    "\n",
    "def minus_to_1():\n",
    "    for i in steam.index:\n",
    "        if steam.loc[i, \"review_score\"] == -1:\n",
    "            steam.loc[i, \"review_score\"] = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULLS TYPES LETTERS_COUNT COMMENT_FILTER\n",
    "steam = pd.read_csv(r'SteamReviews.csv')\n",
    "\n",
    "# int type\n",
    "# print(steam.isnull().sum(axis = 0))\n",
    "steam = steam.astype({'app_id':'int', 'review_score':'int', 'review_votes':'int'})\n",
    "\n",
    "# NULL\n",
    "steam.dropna(inplace = True)\n",
    "\n",
    "# -1 to 0\n",
    "for i in steam.index:\n",
    "        if steam.loc[i, \"review_score\"] == -1:\n",
    "            steam.loc[i, \"review_score\"] = 0\n",
    "\n",
    "# letters counts column\n",
    "steam['letters_count'] = steam['review_text'].apply(lambda x: len(x))\n",
    "\n",
    "# comments\n",
    "steam = steam[steam['letters_count'] > 10]\n",
    "steam = steam[(steam['letters_count'] >= 25) | (steam['review_votes'] == 1)]\n",
    "steam = steam.sort_values('letters_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD FILE_1\n",
    "# steam.to_csv('steam1.csv')\n",
    "steam = pd.read_csv(r'steam1.csv')\n",
    "steam.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "steam = steam.sort_values(\"app_id\")\n",
    "steam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOWER REGEX COMMENT_FILTER\n",
    "def cleanSymbols(text):\n",
    "    res = re.sub(r\"[^a-zA-Z\\s]+\", \"\", text)\n",
    "    return res\n",
    "\n",
    "def cleanLinks(text):\n",
    "    res = re.sub(r\"http\\s+\", \"\", text)\n",
    "    res = re.sub(\"w+://s+\", \"\", res)\n",
    "    return res\n",
    "steam['review_text'] = steam['review_text'].astype(str).str.lower()\n",
    "steam['review_text'] = steam['review_text'].apply(cleanLinks)\n",
    "steam['review_text'] = steam['review_text'].apply(cleanSymbols)\n",
    "\n",
    "# UPDATE LETTERS_COUNT & DELETE COMMENTS\n",
    "steam['letters_count'] = steam['review_text'].apply(lambda x: len(x))\n",
    "steam = steam.sort_values('letters_count')\n",
    "steam = steam[steam['letters_count'] > 10]\n",
    "steam = steam[(steam['letters_count'] >= 25) | (steam['review_votes'] == 1)]\n",
    "steam = steam.sort_values('letters_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD FILE_2 4988035\n",
    "# steam.to_csv('steam2.csv')\n",
    "steam = pd.read_csv(r'steam2.csv')\n",
    "steam.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "steam = steam.sort_values(\"app_id\")\n",
    "steam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENS\n",
    "def delete_long_and_tokenize(text):\n",
    "    res = [w for w in text.split() if len(w) < 20]\n",
    "    if len(res) <= 3:\n",
    "        res = ''\n",
    "    return res\n",
    "steam[\"tokens\"] = steam[\"review_text\"].apply(lambda x: delete_long_and_tokenize(x))\n",
    "steam = steam[steam['tokens'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD FILE_3 TOKENIZED 4787150\n",
    "# steam.to_csv('steam3.csv')\n",
    "steam = pd.read_csv(r'steam3.csv')\n",
    "steam.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "steam = steam.sort_values(\"app_id\")\n",
    "steam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS\n",
    "# nltk.download('stopwords')\n",
    "SW = list(nltk.corpus.stopwords.words(\"english\"))\n",
    "for i in range(len(SW)):\n",
    "    SW[i] = re.sub(r\"[^a-zA-Z]+\", '', SW[i])\n",
    "stop_words = set(SW)\n",
    "\n",
    "def stopwords_cleaner(text):\n",
    "    text = str(text)[2:-2]\n",
    "    text = text.split(\"', '\")\n",
    "    res = [w for w in text if w not in stop_words]\n",
    "    if len(res) <= 4:\n",
    "        return ''\n",
    "    return ' '.join(res)\n",
    "steam['tokens'] = steam['tokens'].apply(stopwords_cleaner)\n",
    "steam = steam[steam['tokens'].str.len() > 0]\n",
    "\n",
    "steam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>best shooter ever buy it or regret it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>best shooter ever buy regret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>ahh csfor many of us born in the s this game t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>ahh csfor many us born game took fps virginity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>this game started the fps franchise well techn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>game started fps franchise well technically st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>epicness ummm you might get addicted xd this g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>epicness ummm might get addicted xd game aweso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>you can already get it free on the offical web...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>already get free offical website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id        app_name  \\\n",
       "0         10  Counter-Strike   \n",
       "3671      10  Counter-Strike   \n",
       "3670      10  Counter-Strike   \n",
       "3669      10  Counter-Strike   \n",
       "3668      10  Counter-Strike   \n",
       "\n",
       "                                            review_text  review_score  \\\n",
       "0                 best shooter ever buy it or regret it             1   \n",
       "3671  ahh csfor many of us born in the s this game t...             1   \n",
       "3670  this game started the fps franchise well techn...             1   \n",
       "3669  epicness ummm you might get addicted xd this g...             1   \n",
       "3668  you can already get it free on the offical web...             0   \n",
       "\n",
       "      review_votes  letters_count  \\\n",
       "0                0             37   \n",
       "3671             0            196   \n",
       "3670             0             93   \n",
       "3669             1             71   \n",
       "3668             1             50   \n",
       "\n",
       "                                                 tokens  \n",
       "0                          best shooter ever buy regret  \n",
       "3671  ahh csfor many us born game took fps virginity...  \n",
       "3670  game started fps franchise well technically st...  \n",
       "3669  epicness ummm might get addicted xd game aweso...  \n",
       "3668                   already get free offical website  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LOAD FILE_4 STOPWORDS 4333260\n",
    "# steam.to_csv('steam4.csv')\n",
    "steam = pd.read_csv(r'steam4.csv')\n",
    "steam.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "steam = steam.sort_values(\"app_id\")\n",
    "steam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>best shooter ever buy it or regret it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>best shooter ever buy regret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>ahh csfor many of us born in the s this game t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>ahh csfor many us born game took fps virginity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>this game started the fps franchise well techn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>game started fps franchise well technically st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>epicness ummm you might get addicted xd this g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>epicness ummm might get addicted xd game aweso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>you can already get it free on the offical web...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>already get free offical website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      app_id        app_name  \\\n",
       "0         10  Counter-Strike   \n",
       "3671      10  Counter-Strike   \n",
       "3670      10  Counter-Strike   \n",
       "3669      10  Counter-Strike   \n",
       "3668      10  Counter-Strike   \n",
       "\n",
       "                                            review_text  review_score  \\\n",
       "0                 best shooter ever buy it or regret it             1   \n",
       "3671  ahh csfor many of us born in the s this game t...             1   \n",
       "3670  this game started the fps franchise well techn...             1   \n",
       "3669  epicness ummm you might get addicted xd this g...             1   \n",
       "3668  you can already get it free on the offical web...             0   \n",
       "\n",
       "      review_votes  letters_count  \\\n",
       "0                0             37   \n",
       "3671             0            196   \n",
       "3670             0             93   \n",
       "3669             1             71   \n",
       "3668             1             50   \n",
       "\n",
       "                                                 tokens  \n",
       "0                          best shooter ever buy regret  \n",
       "3671  ahh csfor many us born game took fps virginity...  \n",
       "3670  game started fps franchise well technically st...  \n",
       "3669  epicness ummm might get addicted xd game aweso...  \n",
       "3668                   already get free offical website  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = steam[steam['app_id'] == 10]\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Milka/nltk_data'\n    - 'c:\\\\Users\\\\Milka\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\nltk_data'\n    - 'c:\\\\Users\\\\Milka\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Milka\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Milka\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Milka\\Documents\\Progs\\Steam-Games-DataAnalysis-\\DataSet\\notebook.ipynb Ячейка 11\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     lemmas \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lem\u001b[39m.\u001b[39mlemmatize(w, get_pos(w)) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m text])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lemmas\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m sub[\u001b[39m'\u001b[39m\u001b[39mlemmas\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sub[\u001b[39m'\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(lem_tokens)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m sub\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Milka\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Milka\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Milka\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1138\u001b[0m             values,\n\u001b[0;32m   1139\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1141\u001b[0m         )\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Milka\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Milka\\Documents\\Progs\\Steam-Games-DataAnalysis-\\DataSet\\notebook.ipynb Ячейка 11\u001b[0m in \u001b[0;36mlem_tokens\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlem_tokens\u001b[39m(text):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39msplit()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     lemmas \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lem\u001b[39m.\u001b[39mlemmatize(w, get_pos(w)) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m text])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lemmas\n",
      "\u001b[1;32mc:\\Users\\Milka\\Documents\\Progs\\Steam-Games-DataAnalysis-\\DataSet\\notebook.ipynb Ячейка 11\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlem_tokens\u001b[39m(text):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39msplit()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     lemmas \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([lem\u001b[39m.\u001b[39mlemmatize(w, get_pos(w)) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m text])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lemmas\n",
      "\u001b[1;32mc:\\Users\\Milka\\Documents\\Progs\\Steam-Games-DataAnalysis-\\DataSet\\notebook.ipynb Ячейка 11\u001b[0m in \u001b[0;36mget_pos\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pos\u001b[39m(w):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     tup \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mpos_tag(w)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m tup[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mN\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Milka/Documents/Progs/Steam-Games-DataAnalysis-/DataSet/notebook.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m wordnet\u001b[39m.\u001b[39mNOUN\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nltk\\tag\\__init__.py:165\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpos_tag\u001b[39m(tokens, tagset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, lang\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    141\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     tagger \u001b[39m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nltk\\tag\\__init__.py:107\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    105\u001b[0m     tagger\u001b[39m.\u001b[39mload(ap_russian_model_loc)\n\u001b[0;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     tagger \u001b[39m=\u001b[39m PerceptronTagger()\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nltk\\tag\\perceptron.py:167\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m load:\n\u001b[0;32m    166\u001b[0m     AP_MODEL_LOC \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m--> 167\u001b[0m         find(\u001b[39m\"\u001b[39;49m\u001b[39mtaggers/averaged_perceptron_tagger/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m PICKLE)\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload(AP_MODEL_LOC)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Milka/nltk_data'\n    - 'c:\\\\Users\\\\Milka\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\nltk_data'\n    - 'c:\\\\Users\\\\Milka\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Milka\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Milka\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# LEMMAS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def get_pos(w):\n",
    "    tup = nltk.pos_tag(w)\n",
    "    if tup[1].startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tup[1].startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tup[1].startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tup[1].startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def lem_tokens(text):\n",
    "    text = text.split()\n",
    "    lemmas = ' '.join([lem.lemmatize(w, get_pos(w)) for w in text])\n",
    "    return lemmas\n",
    "\n",
    "sub['lemmas'] = sub['tokens'].apply(lem_tokens)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the correlation using a heatmap to visualize the data\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(dataset.corr(), annot=True, cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multicollinear feature\n",
    "dataset = dataset.drop('share', axis=1)\n",
    "\n",
    "# Drop features with very low correlation\n",
    "dataset = dataset.drop(['age', 'months'], axis=1)\n",
    "\n",
    "# Plot heamap\n",
    "plt.figure(figsize= (20, 10))\n",
    "sns.heatmap(dataset.corr(), annot=True, cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = dataset.drop('card', axis=1)\n",
    "y = dataset['card']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different parameters\n",
    "params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "logistic_model = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=0, multi_class='ovr'),\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Logistic Regression\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print result\n",
    "accuracy = accuracy_score(logistic_predictions, y_test) * 100\n",
    "print('Accuracy of the model is {:.2f}'.format(accuracy))\n",
    "print(logistic_model.best_params_)\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, logistic_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "plt.savefig('logistic_confusion.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different parameters\n",
    "params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "svm_model = GridSearchCV(\n",
    "    estimator=svm.LinearSVC(random_state=100, max_iter=1000000),\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train SVM \n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "svm_prediction = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print result\n",
    "accuracy = accuracy_score(svm_prediction, y_test) * 100\n",
    "print('Accuracy of the model is {:.2f}'.format(accuracy))\n",
    "print(svm_model.best_params_)\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, svm_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "plt.savefig('svm_confusion.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different parameters\n",
    "params = {\n",
    "    'n_neighbors':  range(1, 15, 2),\n",
    "    'p': [1, 2],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "\n",
    "knn_model = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train KNN\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction\n",
    "knn_prediction = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print result\n",
    "accuracy = accuracy_score(knn_prediction, y_test) * 100\n",
    "print('Accuracy of the model is {:.2f}'.format(accuracy))\n",
    "print(knn_model.best_params_)\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, knn_prediction)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "plt.savefig('knn_confusion.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f731b0747473ad4ab02ec54a65157c483b840cc40ce4e65928751b24444888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
